{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install seaborn library\n",
    "# seaborn: Statistical data visualization library\n",
    "# - Built on top of matplotlib\n",
    "# - Provides enhanced visualization capabilities\n",
    "# - Used for creating informative statistical graphics\n",
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7Y1Uj6N--mr"
   },
   "outputs": [],
   "source": [
    "# Import required libraries for ECG anomaly detection\n",
    "# Purpose: Set up all necessary Python libraries for building an autoencoder\n",
    "\n",
    "# pandas (pd): Data manipulation and analysis\n",
    "# - Used for reading and processing ECG data\n",
    "\n",
    "# numpy (np): Numerical computing library\n",
    "# - Used for array operations and mathematical calculations\n",
    "\n",
    "# matplotlib.pyplot (plt): Plotting library\n",
    "# - Used for visualizing ECG signals and results\n",
    "\n",
    "# tensorflow (tf): Deep learning framework\n",
    "# - Core library for building neural networks\n",
    "\n",
    "# seaborn (sns): Statistical visualization\n",
    "# - Enhanced plotting for statistical graphics\n",
    "\n",
    "# Keras Components:\n",
    "# Sequential: For creating layer-by-layer neural network\n",
    "# Dense: Fully connected neural network layer\n",
    "# Input: For specifying input shape\n",
    "# Dropout: For preventing overfitting\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "170pS0rE_Kop",
    "outputId": "a4ad50a2-2f8d-43c6-b45e-205d4091c0b0"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess ECG data\n",
    "# Purpose: Read ECG data from CSV and prepare it for analysis\n",
    "\n",
    "# 1. Read CSV file containing ECG signals\n",
    "# 2. Remove any rows with missing values using dropna()\n",
    "# 3. Drop unnecessary column '1' using drop()\n",
    "# - axis=1 indicates column removal (axis=0 would be row removal)\n",
    "\n",
    "df = pd.read_csv('ecg.csv').dropna()\n",
    "df = df.drop(['1'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcWxx1WfAUP9",
    "outputId": "f063f74d-51d6-4544-dc7c-5fcd1748766d"
   },
   "outputs": [],
   "source": [
    "# Standardize the ECG data\n",
    "# Purpose: Scale the data to have zero mean and unit variance\n",
    "\n",
    "# StandardScaler: Standardization transformer\n",
    "# - Removes the mean (centering)\n",
    "# - Scales to unit variance\n",
    "# - Important for neural network training stability\n",
    "\n",
    "# fit_transform:\n",
    "# - Learns the scaling parameters from the data\n",
    "# - Applies the transformation to the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = scaler.fit_transform(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23cG4acWAkxn"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "# Purpose: Create separate datasets for training and validation\n",
    "\n",
    "# train_test_split parameters:\n",
    "# - test_size=0.2: 20% of data for testing, 80% for training\n",
    "# - random_state=42: Seed for reproducible results\n",
    "x_train,x_test = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fgw_7oEAtW3",
    "outputId": "e78ccba5-a343-4945-b427-6e54ba83f3f8"
   },
   "outputs": [],
   "source": [
    "# Display dataset shapes\n",
    "# Purpose: Verify the dimensions of training and testing sets\n",
    "\n",
    "# x_train.shape: Shows dimensions of training data\n",
    "# x_test.shape: Shows dimensions of testing data\n",
    "# Helps verify the split ratio and data dimensions\n",
    "print(x_train.shape)\n",
    "# print(y_train.shape)  # Commented out as this is unsupervised learning\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "dR3YVxdcA06g",
    "outputId": "3dda678f-b6d2-4ad0-abaf-1fbcaad98713"
   },
   "outputs": [],
   "source": [
    "# Build Autoencoder Model\n",
    "# Purpose: Create a symmetric autoencoder for anomaly detection\n",
    "\n",
    "model = Sequential([\n",
    "    # Input Layer\n",
    "    Input(shape=(x_train.shape[1],)),  # Match input shape to data dimensions\n",
    "    \n",
    "    # Encoder Layers\n",
    "    Dense(64, activation='relu'),  # Compress to 64 dimensions\n",
    "    Dense(32, activation='relu'),  # Further compress to 32 dimensions\n",
    "    Dense(16, activation='relu'),  # Bottleneck layer - 16 dimensions\n",
    "    \n",
    "    # Decoder Layers - Mirror the encoder architecture\n",
    "    Dense(32, activation='relu'),  # Start expanding back\n",
    "    Dense(64, activation='relu'),  # Continue expanding\n",
    "    Dense(x_train.shape[1], activation='linear')  # Output layer matching input dimensions\n",
    "])\n",
    "\n",
    "# Compile the model:\n",
    "# optimizer='adam': Adaptive learning rate optimization\n",
    "# loss='mse': Mean Squared Error loss for reconstruction\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Display model architecture summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lk4sR6QLCl_S",
    "outputId": "aa8c57d4-e818-4c43-d2cf-eb2e00b0b470"
   },
   "outputs": [],
   "source": [
    "# Train the Autoencoder\n",
    "# Purpose: Train the model to reconstruct normal ECG patterns\n",
    "\n",
    "# Parameters:\n",
    "# x_train, x_train: Same data for input and target (autoencoder property)\n",
    "# epochs=50: Number of complete passes through the training data\n",
    "# batch_size=30: Number of samples per gradient update\n",
    "# validation_data: Test data for monitoring performance\n",
    "# shuffle=True: Randomize batch order in each epoch\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=30,\n",
    "    validation_data=(x_test,x_test),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "RPVWPCB-DCjm",
    "outputId": "1def2165-4e50-48c7-cd13-15ba5002451e"
   },
   "outputs": [],
   "source": [
    "# Visualize Training History\n",
    "# Purpose: Plot training and validation loss over epochs\n",
    "\n",
    "# sns.lineplot: Create line plot of training metrics\n",
    "# model.history.history: Contains loss values for each epoch\n",
    "import seaborn as sns\n",
    "sns.lineplot(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNMTNcqjDYIg",
    "outputId": "90754a2e-4d37-4867-d571-bd6110be2b1d"
   },
   "outputs": [],
   "source": [
    "# Calculate Reconstruction Error and Set Threshold\n",
    "# Purpose: Identify anomalies based on reconstruction performance\n",
    "\n",
    "# 1. Get model predictions (reconstructions)\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# 2. Calculate Mean Squared Error between original and reconstructed data\n",
    "# np.power(x_test - predictions, 2): Square the differences\n",
    "# np.mean(..., axis=1): Average across features for each sample\n",
    "mse = np.mean(np.power(x_test - predictions, 2), axis=1)\n",
    "\n",
    "# 3. Set threshold at 95th percentile of MSE values\n",
    "# Samples with MSE > threshold will be considered anomalies\n",
    "threshold = np.percentile(mse, 95)  # Top 5% are anomalies\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-0jZVh-DfUJ"
   },
   "outputs": [],
   "source": [
    "# Create Boolean Mask for Anomalies\n",
    "# Purpose: Identify anomalous ECG signals\n",
    "\n",
    "# mse > threshold returns boolean array:\n",
    "# - True: Sample is an anomaly (MSE > threshold)\n",
    "# - False: Sample is normal (MSE <= threshold)\n",
    "anomalies = mse > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yY56_J6-DhrZ",
    "outputId": "8dbfd771-008e-495e-a46f-d6f8c967f2ef"
   },
   "outputs": [],
   "source": [
    "# Count Total Anomalies\n",
    "# Purpose: Quantify the number of detected anomalous ECG signals\n",
    "\n",
    "# np.sum(anomalies): Count True values in boolean array\n",
    "# This represents the total number of anomalous samples\n",
    "num_anomalies = np.sum(anomalies)\n",
    "print(f\"Number of Anomalies: {num_anomalies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "MMY75QJxDlCB",
    "outputId": "e9b1a4a8-b6ec-4a0e-99d9-2116f39259bf"
   },
   "outputs": [],
   "source": [
    "# Visualize Reconstruction Errors\n",
    "# Purpose: Plot MSE distribution and anomaly threshold\n",
    "\n",
    "# Plot components:\n",
    "# - Blue dots: MSE for each sample\n",
    "# - Red line: Anomaly threshold\n",
    "# - Points above red line are anomalies\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "plt.plot(mse, marker='o', linestyle='', markersize=3, label='MSE')\n",
    "plt.axhline(threshold, color='r', linestyle='--', label='Anomaly Threshold')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Anomaly Detection Results')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "V9OBO9gaDoGq",
    "outputId": "5005df94-b14a-41e3-8618-81aed59e8657"
   },
   "outputs": [],
   "source": [
    "# Visualize Normal ECG Reconstruction\n",
    "# Purpose: Compare original and reconstructed ECG signals\n",
    "\n",
    "# Plot parameters:\n",
    "# figsize=(12, 6): Set figure dimensions\n",
    "# x_test[0]: Original signal (first sample)\n",
    "# predictions[0]: Reconstructed signal\n",
    "# Shows how well the autoencoder reconstructs normal patterns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(x_test[0], label='Original ECG')\n",
    "plt.plot(predictions[0], label='Reconstructed ECG')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.title('Normal ECG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "_l3NB3KEDr68",
    "outputId": "ff33f969-bfe6-4e0a-9d67-d2c6acf35179"
   },
   "outputs": [],
   "source": [
    "# Create Confusion Matrix\n",
    "# Purpose: Visualize the classification results\n",
    "\n",
    "# Note: In unsupervised anomaly detection, we're comparing\n",
    "# predictions against themselves to visualize distribution\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Create and plot confusion matrix\n",
    "sns.heatmap(confusion_matrix(anomalies, anomalies), annot=True, fmt='d')\n",
    "plt.xlabel(\"Predicted label\", fontsize=14)\n",
    "plt.ylabel(\"True label\", fontsize=14)\n",
    "plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5uX27rSDwOr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
